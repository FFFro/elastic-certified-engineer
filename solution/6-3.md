## Question
```text
# ** EXAM OBJECTIVE: MAPPINGS AND TEXT ANALYSIS **
# GOAL: Add built-in text analyzers and specify a custom one
# REQUIRED SETUP:
# (i) a running Elasticsearch cluster with at least one node
# and a Kibana instance,
# (ii) the cluster has no index with name `hamlet`,
# (iii) the cluster has no template that applies to indices
# starting by `hamlet`

# Create the index `hamlet_1` with one primary shard and no replicas
# Define a mapping for the default type "_doc" of `hamlet_1`, so
# that (i) the type has three fields, named `speaker`,
# `line_number`, and `text_entry`, (ii) `text_entry` is
# associated with the language "english" analyzer
# Add some documents to `hamlet_1` by running the following commandPUT
hamlet_1/_doc/_bulk
{"index":{"_index":"hamlet_1","_id":0}}
{"line_number":"1.1.1","speaker":"BERNARDO","text_entry":"Whos
there?"}
{"index":{"_index":"hamlet_1","_id":1}}
{"line_number":"1.1.2","speaker":"FRANCISCO","text_entry":"Nay, 
answer me: stand, and unfold yourself."}
{"index":{"_index":"hamlet_1","_id":2}}
{"line_number":"1.1.3","speaker":"BERNARDO","text_entry":"Long live
the king!"}
{"index":{"_index":"hamlet_1","_id":3}}
{"line_number":"1.2.1","speaker":"KING CLAUDIUS","text_entry":"Though
yet of Hamlet our dear brothers death"}

# Create the index `hamlet_2` with one primary shard and no replicas
# Add to `hamlet_2` a custom analyzer named `shy_hamlet_analyzer`,
# consisting of
# (i) a char filter to replace the characters "Hamlet" with "
# [CENSORED]",
# (ii) a tokenizer to split tokens on whitespaces and columns,
# (iii) a token filter to ignore any token with less than 5
# characters # Define a mapping for the default type "_doc" of
`hamlet_2`, so
# that (i) the type has one field named `text_entry`, (ii)
# `text_entry` is associated with the `shy_hamlet_analyzer`
# created in the previous step

# Reindex the `text_entry` field of `hamlet_1` into `hamlet_2`
# Verify that documents have been reindexed to `hamlet_2` as
# expected - e.g., by searching for "censored" into the
# `text_entry` field
```
# Answer
```text
DELETE hamlet*
DELETE _template/*
PUT hamlet_1
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  }
}
PUT hamlet_1/_mapping
{
  "properties": {
    "speaker": {
      "type": "text"
    },
    "line_number": {
      "type": "text"
    },
    "text_entry": {
      "type": "text",
      "analyzer": "english"
    }
  }
}
PUT hamlet_1/_doc/_bulk
{"index":{"_index":"hamlet_1","_id":0}}
{"line_number":"1.1.1","speaker":"BERNARDO","text_entry":"Whos there?"}
{"index":{"_index":"hamlet_1","_id":1}}
{"line_number":"1.1.2","speaker":"FRANCISCO","text_entry":"Nay, answer me: stand, and unfold yourself."}
{"index":{"_index":"hamlet_1","_id":2}}
{"line_number":"1.1.3","speaker":"BERNARDO","text_entry":"Long live the king!"}
{"index":{"_index":"hamlet_1","_id":3}}
{"line_number":"1.2.1","speaker":"KING CLAUDIUS","text_entry":"Though yet of Hamlet our dear brothers death"}

DELETE hamlet_2
PUT hamlet_2
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0,
    "analysis": {
      "analyzer": {
        "shy_hamlet_analyzer": {
          "type": "custom",
          "tokenizer": "whitespace",
          "char_filter": [
            "hamlet_filter"
          ],
          "filter": [
            "hamlet_filter"
          ]
        }
      },
      "char_filter": {
        "hamlet_filter": {
          "type": "mapping",
          "mappings": [
            "Hamlet => [CENSORED]"
          ]
        }
      },
      "filter": {
        "hamlet_filter": {
          "type": "length",
          "min": 5
        }
      }
    }
  }
}
PUT hamlet_2/_mapping
{
  "properties": {
    "text_entry": {
      "type": "text",
      "analyzer": "shy_hamlet_analyzer"
    }
  }
}

POST _reindex
{
  "source": {
    "index": "hamlet_1"
  },
  "dest": {
    "index": "hamlet_2"
  }
}
POST hamlet_2/_analyze
{
  "analyzer": "shy_hamlet_analyzer",
  "text": "Though yet of Hamlet our dear brothers death"
}
GET hamlet_2/_search
{
  "query": {
    "match": {
      "text_entry": "[CENSORED]"
    }
  }
}
```
## Knowledge points
```text
"filter": {
          "my_condition": {
            "type": "condition",  
            "filter" : [ "lowercase" ],
            "script": {
              "source": "token.getTerm().length() < 5"
            }
          }
        }
```
## Some can't answer
* char filter mapping的格式
* token filter 忽略小于 5的